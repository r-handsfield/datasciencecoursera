---
title: "c6w2l2"
author: "Robert Handsfield"
date: "04/19/2015"
output:
  html_document:
    toc: yes
---

# 0501 The Variance

Variance measures a random variable's spread about it's mean. 

$$Var(X) = E[(X-\mu)^2] = E[X^2] - E[X]^2$$

Variance is converted to standard deviation simply to move from units of $X^2$ to units of $X$.

$$SD(X) = \sqrt{Var(X)}$$

## Examples of Calculating the Variance

### Example 1 - Calculate the Variance of a Die Roll

$$Var(X) = E[X^2] - E[X]^2$$

$E[X]=3.5$

$E[X^2] = 1^2 \times {1 \over 6} + 2^2 \times {1 \over 6} + 3^2 \times {1 \over 6} + 4^2 \times {1 \over 6} + 5^2 \times {1 \over 6} + 6^2 \times {1 \over 6} = 15.17$

$Var(X) = E[X^2] - E[X]^2 = 15.17 - 3.5^2 \approx  2.92$


### Example 2 - Calculate the Variance of a Coin Toss
What's the variance from the result of a coin toss with probability of heads(1) of $p$?

$$Var(X) = E[X^2] - E[X]^2$$

$E[X] = 0 \times (1 - p) + 1 \times p = p$

$E[X^2] = 0^2 \times (1-p) + 1^2 \times p = p$ 

$Var(X) = E[X^2] - E[X]^2 = p - p^2 = p(1 - p)$


## 0502 Sample Variance vs Population Variance
Just like a sample's mean is analogous to its population mean:

1. The population mean is the center (of mass) of the _population distribution_
2. The sample mean is the center (of mass) of the _observed data_
3. The sample mean is always an estimate of the population mean
4. The sample mean is unbiased
	+ The population mean of the sample mean distribution is the mean that the sample mean is trying to estimate
5. The more observations in the sample mean, the more its mass/density function concentrates around the population mean

A sample's variance is analogous to its population variance:

1. The population variance is the expected squared distance between a random variable and the population mean
	+ $Var(X) = \sigma^2 = {\frac{\sum_{i=1} (X_i - \mu)^2}{n-1}} = E[(X-\mu)^2] = E[X^2] - E[X]^2$
2. The sample variance is the expected squared distance between the observed values and the sample mean
	+ $S^2 = Var({X_s}) = \frac{\sum_{i=1} (X_{si} - \bar X_s)^2}{n-1}$
3. The sample variance is also a random variable with a population distribution
4. The expected value of the sample variance converges to the population variance as sample size increases
	+ See _Example 4_
5. The sample variance estimates the population variance
	+ As sample size increases, the distribution of the samples' variance values collapses around the population variance

> __Sample Variance__ means _The Variance of One Sample from a Population_
> $$S^2 = \frac{\sum_{i=1} (X_i - \bar X)^2}{n-1}$$


### Example 3 - Simulating from a population with variance 1

1. Simulate 10 standard normal distributions
2. Calculate & plot the sample variance: $Var(X) = E[X^2] - E[X]^2$
3. Repeat 10,000 times
4. Repeat for 20 and 30 standard normals

The mean of each set of samples' variances is at 1: $E[Var(X)] = 1$, which we expect. As we sample from more standard normals, the variance of the samples' variance collapses around 1; the estimate becomes more precise.

> More data yields a better, more concentrated estimate around whatever the samples' variance is trying to estimate.

Plotting the variance distribution from 10 standard normals gives the lowest curve, 20 gives the middle, 30 gives the top curve.

```{r, fig.height=6, figh.width=6, fig.align='center', echo = FALSE}
library(ggplot2)
nosim <- 10000; 
dat <- data.frame(
    x = c(apply(matrix(rnorm(nosim * 10), nosim), 1, var),
          apply(matrix(rnorm(nosim * 20), nosim), 1, var),
          apply(matrix(rnorm(nosim * 30), nosim), 1, var)),
    n = factor(rep(c("10", "20", "30"), c(nosim, nosim, nosim))) 
    )
ggplot(dat, aes(x = x, fill = n)) + geom_density(size = 2, alpha = .2) + geom_vline(xintercept = 1, size = 2) + xlab("Variance Value")

```


### Example 4 - Variances of x die rolls
The variance of a die roll is $2.92$ (from example 1).

$E[X]=3.5$

$E[X^2] = 1^2 \times {1 \over 6} + 2^2 \times {1 \over 6} + 3^2 \times {1 \over 6} + 4^2 \times {1 \over 6} + 5^2 \times {1 \over 6} + 6^2 \times {1 \over 6} = 15.17$

$Var(X) = E[X^2] - E[X]^2 = 15.17 - 3.5^2 \approx  2.92$

1. Roll a sample of 10 dice
2. Find the variance of the 10 results
3. Repeat 10,000 times 
4. Plot the 10,000 variance values
	+ (each of these values is a sample variance $S^2$)
5. The mean value of the resulting distribution will be $2.92$


```{r, fig.align='center',fig.height=5, fig.width=10, echo = FALSE, warning=FALSE, error=FALSE, message=FALSE}
library(ggplot2)
nosim <- 10000;
dat <- data.frame(
  x = c(
  	apply(
  	      	matrix(
  			sample(1 : 6, nosim * 10, replace = TRUE), nosim), 
  	      	1, var),
  	
        apply(
              	matrix(
              	     	sample(1 : 6, nosim * 20, replace = TRUE), nosim), 
              	1, var),
        
        apply(
        	matrix(
       			sample(1 : 6, nosim * 30, replace = TRUE), nosim), 
        	1, var)
        ),
  size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black") 
g <- g + geom_vline(xintercept = 2.92, size = 2) + xlab("Variance Values")
g + facet_grid(. ~ size)
```

Doing the same thing with 20 and 30 dice gives the same mean ($2.92$), with tighter distributions of sample variances. As sample size increases, the estimate of the population variance (mean of all the sample variances) becomes more precise.

> The average of all the samples' variances is a good estimate of population variance, _if_ the sampling is unbiased (random)

## 0503 Standard error of the mean

Recall some traits about the distributions of sample means

1. If we take a random sample from a population, and calculate the sample's mean value, that average is itself a random variable
2. That random variable has _its own_ population mean and population variance
3. The population distribution of this variable is centered around mean of the _original_ population: $E[\bar X] = \mu$
4. That variable's population variance is $Var({\overline{X}}) = \sigma^2 / n$
	+ where $n$ is the size of a sample
	+ __The variance in a sample decreases linearly as sample size increases__
5. We usually know $n$, can often estimate $\sigma^2$, and measure $Var(\overline{X})$



> The __Standard Error__ of the Mean is the square root of the __variance of the sample mean__: $Var({\overline{X}}) = \sigma^2 / n$
> $${SE_\overline{x}} = {\sigma / \sqrt{n}} \approx {S / \sqrt{n}}$$

Standard Error is the variability of the sample population's average value, and represents the precision of the estimate. As sample size increases, standard error decreases; at infinite samples, the standard error is zero. 

(Any quantity can be estimated and have a standard error - mean, median, variance, regression coefficients, etc.)
	
### Summary of standard error

1. The standard error is the standard deviation of any population _statistic_
2. Standard error is the variability of a sample's average value
3. Standard error converges to the standard deviation $\sigma$ as sample size increases
4. $SE_x = \sqrt{Var(\bar{X})} = {\sqrt{S_{X}^{2}}} = {\sigma/ \sqrt{n}} \approx {S / \sqrt{n}}$ 

1. A sample's variance $S^2$ estimates the population variance $\sigma^2$
3. The distribution of a sample's variance $S^2$ is centered around the "true" value $\sigma^2$
4. That distribution becomes more concentrated as sample size $n$ increases
5. Similarly, the sample mean $\bar{X}$ estimates the population mean $\mu$
5. The sample mean's distribution is centered around $\mu$
6. The sample mean's distribution becomes more concentrated as sample size $n$ increases
7. The variance of a sample converges exactly to $\sigma^2 /n$
	+ with real data, draw many samples, yielding many sample means, to estimate $\sigma^2$
 
	

## 0504 Variance Example
The father/son data set contains height measurements of fathers and their sons.
```{r echo=FALSE, message=FALSE}
library(UsingR); data(father.son);
x <- father.son$sheight
n <- length(x) # num observations
```

Sons' heights look Gaussian. This variance of this plot _estimates_ the height 
variability of whatever population this set came from (caucasian, african, etc.)
```{r}

hist(x, plot=TRUE, breaks=seq(58, 80), probability=TRUE)
lines(density(x), col="red", lwd=3)
```

Values for this plot of childrens' heights

* Population Variance $(\sigma^2)$: `r round(var(x), 2)` 
* Sample Variance $({S^2})$: `r round(var(x)/n, 2)` 
* Standard Deviation $(\sigma)$: `r round(sd(x), 2)` 
* Standard Error $({\sigma}/{\sqrt{n}})$: `r round(sd(x)/sqrt(n), 2)` 

The samples' variance and Standard Error measure the variance and deviation of the
height _averages_ in groups of $n$ children.

### Summary of Variances

0. A sample's variance is a random variable (sample variance) that has its own distribution and mean
1. The distribution of the sample variance $S^2$ is centered at whatever it is estimating
2. The distribution of the sample variance $S^2$ gets more concentrated around 
the population variance $(\sigma^2)$ as $n$ increases
3. The variance of the sample mean: $Var(\overline{X}) = {\sigma^2}/n$ __estimates__ the population variance $(\sigma^2)$
5. The variance of the sample represents the variability of values drawn from a population
6. The standard error represents the variability of sample means, for samples drawn from a population


## 0601 Common Distributions - Bernoulli & Binomial

### The Bernoulli Distribution

0. Obtained from a binary system
1. Bernoulli random variables take only the values $0$ and $1$
2. Bernoulli random variables have probabilities of only __$p$__ and __$1-p$__
4. The mean and variance of any Bernoulli random variable are __$p$__ and __$p(1-p)$__

The Bernoulli probability mass function (PMF) is $P(X=x) = {p^x}(1-p)^{1-x}$

### The Binomial Distribution

1. A binomial random variable is the sum of several Bernoulli variables
	+ EX: the total number of heads from coin flips

If $X_n$ are iid $Bernoulli(p)$  (Bernoulli variables), then the binomial random
variable is defined as 
$$X = \sum_{i=1}^{n}X_i$$

The binomial probability mass function (PMF) is $P(X=x) = \binom{n}{x}{p^x}(1-p)^{n-x}$

(\binom{n}{x} is "n choose x", the number of combinations of $n$ and $x$)

#### Example of a binomial calculation

A friend has 8 children; 7 girls and 1 boy.

If each gender has an independent 50% probability for each birth, what is the 
probability of getting 7 __or more__ girls out of 8 births?

Two positive conditions: $7$ girls or $8$ girls,  $\therefore P(X) = P(7) + P(8)$

$$P(X=x) = \binom{n}{x}{p^x}(1-p)^{n-x}$$
$$P(X=7) = \binom{8}{7}{p^7}(1-p)^{8-7} = \binom{8}{7}{.5^7}(1-.5)^{8-7}$$
$$P(X=8) = \binom{8}{8}{.5^8}(1-.5)^{8-8}$$

$$P(7) + P(8) \approx 0.04$$

Code by:
```{r}
# library("combinat");
choose(8,7) * .5^7 * (1-.5)^(8-7) + choose(8,8) * .5^8 * (1-.5)^(8-8)

# simplifies to 
choose(8,7) * .5^8 + choose(8,8) * .5^8

# can also use pbinom *** q > 6 = {7,8}
pbinom(q = 6, size = 8, prob = .5, lower.tail = FALSE)  # lower.tail false means p(X > x)
```


## 0602 The Normal Distribution




## 0603 The Poisson Distribution








