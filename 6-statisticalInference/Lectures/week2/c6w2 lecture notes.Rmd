---
title: "c6w2l2"
author: "Robert Handsfield"
date: "04/19/2015"
output:
  html_document:
    toc: yes
---

# 0501 The Variance

Variance measures a random variable's spread about it's mean. 

$$Var(X) = E[(X-\mu)^2] = E[X^2] - E[X]^2$$

Variance is converted to standard deviation simply to move from units of $X^2$ to units of $X$.

$$SD(X) = \sqrt{Var(X)}$$

## Examples of Calculating the Variance

### Example 1 - Calculate the Variance of a Die Roll

$$Var(X) = E[X^2] - E[X]^2$$

$E[X]=3.5$

$E[X^2] = 1^2 \times {1 \over 6} + 2^2 \times {1 \over 6} + 3^2 \times {1 \over 6} + 4^2 \times {1 \over 6} + 5^2 \times {1 \over 6} + 6^2 \times {1 \over 6} = 15.17$

$Var(X) = E[X^2] - E[X]^2 = 15.17 - 3.5^2 \approx  2.92$


### Example 2 - Calculate the Variance of a Coin Toss
What's the variance from the result of a coin toss with probability of heads(1) of $p$?

$$Var(X) = E[X^2] - E[X]^2$$

$E[X] = 0 \times (1 - p) + 1 \times p = p$

$E[X^2] = 0^2 \times (1-p) + 1^2 \times p = p$ 

$Var(X) = E[X^2] - E[X]^2 = p - p^2 = p(1 - p)$


## 0502 Sample Variance vs Population Variance
Just like sample mean is analogous to population mean:

2. The population mean is the center (of mass) of the _population distribution_
3. The sample mean is the center (of mass) of the _observed data_
4. The sample mean is always an estimate of the population mean
5. The sample mean is unbiased
	+ The population mean of the sample mean distribution is the mean that the sample mean is trying to estimate
6. The more observations in the sample mean, the more it's mass/density function concentrates around the population mean

The sample variance is analogous to the population variance:

1. The population variance is the expected squared distance between a random variable and the population mean
	+ $Var(X) = E[(X-\mu)^2] = E[X^2] - E[X]^2$
2. The sample variance is the average squared distance between the observed values and the sample mean
	+ $S^2 = \frac{\sum_{i=1} (X_i - \bar X)^2}{n-1}$
3. The variance of the sample variance is also a random variable with a population distribution
4. The expected value of the sample variance's variance is the population variance, which the sample variance is trying to estimate
	+ As samples increase, the distribution of the sample variance collapses around the population variance


### Example 3 - Simulating from a population with variance 1

1. Simulate 10 standard normal distributions
2. Calculate & plot their sample variances: $Var(X) = E[X^2] - E[X]^2$
3. Repeat 10,000 times
4. Repeat for 20 and 30 standard normals

The mean of each set of sample variances is at 1: $E[Var(X)] = 1$, which we expect. As we sample from more standard normals, the variance of the sample variance collapses around 1; the estimate becomes more precise.

> More data yields a better, more concentrated estimate around whatever the sample variance is trying to estimate.

Plotting the variance distribution from 10 standard normals gives the lowest curve, 20 gives the middle, 30 gives the top curve.

```{r, fig.height=6, figh.width=6, fig.align='center', echo = FALSE}
library(ggplot2)
nosim <- 10000; 
dat <- data.frame(
    x = c(apply(matrix(rnorm(nosim * 10), nosim), 1, var),
          apply(matrix(rnorm(nosim * 20), nosim), 1, var),
          apply(matrix(rnorm(nosim * 30), nosim), 1, var)),
    n = factor(rep(c("10", "20", "30"), c(nosim, nosim, nosim))) 
    )
ggplot(dat, aes(x = x, fill = n)) + geom_density(size = 2, alpha = .2) + geom_vline(xintercept = 1, size = 2) 

```


### Example 4 - Variances of x die rolls
The variance of a die roll is $2.92$ (from example 1).

$E[X]=3.5$

$E[X^2] = 1^2 \times {1 \over 6} + 2^2 \times {1 \over 6} + 3^2 \times {1 \over 6} + 4^2 \times {1 \over 6} + 5^2 \times {1 \over 6} + 6^2 \times {1 \over 6} = 15.17$

$Var(X) = E[X^2] - E[X]^2 = 15.17 - 3.5^2 \approx  2.92$

If I roll 10 dice, take the sample variance of all their results (1-6), and plot the sample variances, the mean of those sample variances is 2.92.
```{r, fig.align='center',fig.height=5, fig.width=10, echo = FALSE, warning=FALSE, error=FALSE, message=FALSE}  
dat <- data.frame(
  x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE), 
                     nosim), 1, var),
        apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE), 
                     nosim), 1, var),
        apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE), 
                     nosim), 1, var)
        ),
  size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black") 
g <- g + geom_vline(xintercept = 2.92, size = 2)
g + facet_grid(. ~ size)
```

Doing the same thing with 20 and 30 dice gives the same mean ($2.92$), with lower variance. As samples increase, the estimate of the population variance (mean of the sample variances) becomes more precise.

> The sample variance is a good estimate of population variance, _if_ the sampling is unbiased (random)

## 0503 Standard error of the mean

Recall some traits about the distributions of sample means

1. If we take a random sample from a population, and calculate the sample's average, the average is itself a random variable
2. That random variable average has _it's own_ population mean and population variance
3. That average's population mean is the same as the mean of the _original_ population: $E[\bar X] = \mu$
4. That average's population variance is related to the variance of the _original_ population by $Var(\bar X) = \sigma^2 / n$
	+ where $n$ is the number of samples
	+ __The sample variance decreases linearly with number of samples__
5. We usually know $n$, can often estimate $\sigma^2$, and measure $Var(\bar{X})$

The quantity $\sigma^2 /n$ is called the ___Standard Error__. It's the variance of the sample population's average value, and represents the ~precision~ of the estimate. As samples increase, standard error decreases; at infinite samples, the standard error is zero. 

(Any quantity can be estimated and have a standard error - mean, median, variance, regression coefficients, etc.)
	
### Summary of standard error

1. The sample variance $S^2$ estimates the population variance $\sigma^2$
3. The distribution of the sample variance $S^2$ is centered around the "true" value $\sigma^2$
4. That distribution becomes more concentrated as number of samples $n$ increases
5. Similarly, the sample mean $\bar{X}$ estimates the population mean $\mu$
5. The sample mean's distribution is centered around $\mu$
6. The sample mean's distribution becomes more concentrated as number of samples $n$ increases
7. The variance of the sample mean is __exactly__ $\sigma^2 /n$
	+ with real data, draw many samples, yielding many sample means, to estimate $\sigma^2$
	



























