---
title: "c6w4p1"
author: "R. Handsfield"
date: "January 10, 2016"
output:
  # html_document: default
  pdf_document:
    latex_engine: xelatex
---

<style type="text/css">
	.panel_pinkish{
		background-color: lavenderblush;
		padding: 5px;
	}
	
	.math_list > ul > li {
		/*extra space to accomodate LaTeX figures*/
		margin-bottom: 3px;
	}
</style>

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2);
library(gridExtra);

set.seed(15112);
```


# Abstract

In this project, we compare the [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution) to the Central Limit Theorem. Simulated exponential distributions of $n = 40$ are sampled from an ideal exponential distribution with rate parameter $\lambda = 0.2$.

# Overview

The exponential distribution, also known as the _Poisson_ distribution, is often
used to measure rates. The probability density and cumulative probability distributions are 

$$
f(x;\lambda) = \left\{\begin{matrix} 
 \lambda e^{- \lambda x} & x \geq 0 \\ 
 0 & x < 0 
\end{matrix}\right.
 ~~~~~~~~~~ ~~~~~~~~~~
F(x;\lambda) = \left\{\begin{matrix} 
 1 - e^{- \lambda x} & x \geq 0 \\ 
 0 & x < 0
\end{matrix}\right.
$$

The parameter _lambda_ is known as the _rate parameter_, and is directly related to the mean and standard deviation.
$$\mu = \frac{1}{\lambda} ~~~~~~~~~~ ~~~~~~~~~~ \sigma = \frac{1}{\lambda}$$


Plots of the exponential distribution look like this

<div class="panel_pinkish">
```{r echo=FALSE, fig.align='center', fig.width=(7), fig.asp=.5, warning=FALSE}
x <- seq(0,5,.01)
df <- data.frame(x, dexp(x), pexp(x), rexp(x) );
names(df) <- c("x", "exp.dens", "exp.dist", "exp.sim");

h <- ggplot(data=df) + aes(x=x, y=exp.dist) + geom_line();
h <- h + ggtitle("Cumulative Distribution") + ylab("P(X â‰¤ x)");

g <- ggplot(data=df) + aes(x=x, y=exp.dens) + geom_line();
g <- g + ggtitle("Probability Density") + ylab("P(x)");

grid.arrange(g,h, ncol=2, top="");
```
</div>

# Simulations

We create each comparison distribution by sampling 40 values randomly from the exponential distribution.
We simulate a total of 1000 comparisons; the mean of each simulation ($\bar X$) is calculated, resulting in a list of 1000 simulated means. 


```{r cache=TRUE, message=FALSE}

means <- NULL;  # initialize list of means

for( i in 1:1000 ){
# 	print(i);
	sim <- rexp(40, rate=0.2); # simulate 40 values with lambda = 0.2
	means <- c(means, mean(sim));  # calculate means
}
```
```{r}
mean(means);
var(means);
```
```{r echo=FALSE}
M <- signif(mean(means),3);
V <- signif(var(means),3);
```
<br />
According to the Central Limit Theorem, the average of these 1000 means should be a fairly accurate estimate of the true population mean $\mu$. The means should be normally distributed, with a variance proportional to the number of values in each simulation (40).

```{r eval=FALSE, echo=FALSE}
# vectorised simulation & calculation // time this later
sds <- rep(NA, 1000)
df <- data.frame(mns=sds, sds=sds)
df$mns <- sapply(1:1000, function(x) {mean(rexp(40, 0.2))})
df$sds <- sapply(1:1000, function(x) {sd(rexp(40, 0.2))})
head(df)

apply(df, 2, mean)
```
 

## Sample Mean vs Population Mean

The average of simulated means is the ___Sample Mean:___ $\bar X_{\mu} =$ `r M`. 

The population mean of the exponential distribution is
$$~ \mu = \frac{1}{\lambda} = \frac{1}{0.2} = 5.0$$

`r M` seems close to $5.0$, but how close of an estimate is this? We can figure it out by looking at the distribution of simulated means.

The histogram of simulated means is: 
```{r warning=FALSE, message=FALSE}
gm <- ggplot() + aes(x=means) + ggtitle("Sample Means"); 
gm <- gm + geom_histogram(aes(y=..density..), color='black', fill='lightblue');
gm <- gm + geom_vline(xintercept = 5, size=2, color='red');

gm
```

The 1000 simulated means are normally distributed and centered near the true population mean $\mu$ (red line). Because the means are normally distributed, we can use normal statistics to determine how good of an estimte `r M` actually is.

The probability of the sample means randomly centering at `r M` is:
```{r}
1 - 2*(pnorm( abs( mean(means)-5 ), mean=0, sd=sd(means), lower.tail = FALSE) )
```

There is a probability of just a few chances out of 100 that our sample mean estimates a non-exponential population mean, but randomly averages to a value near $5.0$.

## Variance of the Sample Mean

According to the central limit theorem, a sample estimates a statistic, and has variance proportional to the sample size $n$.

$$Var(\bar X) = \left( \frac{\sigma}{\sqrt n}\right)^2$$

For the exponential distribution
$$Var(\bar X) = \left( \frac{1}{\lambda \sqrt n} \right)^{2} = \left( 0.2 \sqrt {40}\right)^{-2} = 0.625$$

The variance of the sample mean is
```{r}
var(means);
```
It appears that the sample variance slightly underestimates the population variance.

## Distribution of the Sample Mean

Overlaying a normal distribution plot on the the histogram of means shows that the distribution of means is approximately normal.
```{r, warning=FALSE, message=FALSE}
# add normal distribution plot to histograms
gm <- gm + stat_function(fun=dnorm, args=list(mean=5, sd=sd(means)), size=2)
gm
```

# Conclusion

The simulated distributions yield the following statistic.

* Sample Mean: `r M`
* Variance of Sample Mean: `r V`

Both are in good agreement with the predictions of the central limit theorem.

Distribution of simulated means is approximately normal.


---

# Part 2

# Abstract

In this project, we analyze the `datasets::ToothGrowth` data set to determine the effect Vitamin C supplement and dosage on the average tooth length of guinea pigs. We use exploratory analysis and hypothesis testing to achieve our results.

## Overview

The `ToothGrowth` dataset reports the effect of Vitamin C on tooth growth in guinea pigs. The data frame contains 3 columns representing, _tooth length_, _supplement type_, and _dose (mg)_.

# Exploratory Analysis
```{r}
library("datasets")
data(ToothGrowth)
```

```{r}
dftg <- ToothGrowth
head(dftg)
str(dftg)
table(dftg[, c('supp','dose')])
```

```{r eval=FALSE, echo=FALSE}
table(dftg[dftg$supp == 'VC', 'dose'])
dftg[dftg$supp == 'OJ', 'dose']
```
There are two treatments (OJ and VC), each administered at 3 different dosages to independant groups of 10 guinea pigs. 

```{r}
g <- ggplot(dftg) + aes(x=factor(dose), y=len, fill=factor(dose)) + geom_boxplot()
g <- g + facet_grid(.~supp) + xlab("Dose (mg)") + ylab("Tooth Length")
g
```


# Comparing Treatments

* Assumption: The means of each pair of experimental groups are equal.
* $H_0 : \mu_1 = \mu_2$
* $H_a : \mu_1 \neq \mu_2$ 
	
```{r}
# subset individual groups
df_oj <- dftg[dftg$supp=='OJ',]
df_vc <- dftg[dftg$supp=='VC',]

df_half <- dftg[dftg$dose==0.5,]
df_one <- dftg[dftg$dose==1,]
df_two <- dftg[dftg$dose==2,]
```

Summary of Mean Tooth Lengths

| Group | Mean Length |
|-------|-------------|
| OJ | `r round(mean(df_oj$len),3)` |
| VC | `r round(mean(df_vc$len),3)` |
| 0.5 mg | `r round(mean(df_half$len),3)` |
| 1.0 mg | `r round(mean(df_one$len),3)` |
| 2.0 mg | `r round(mean(df_two$len),3)` |

The means of the supplement and dosage groups are all distinct, but are they different enough to suggest that each experimental parameter had an effect?

## T-Testing

Comparing standard errors of each experimental group tells us whether we should use equal variance t-tests.
```{r}
data.frame(group=c('OJ', 'VC', '0.5 mg', '1 mg', '2 mg'), 
	   std.error= c(sd(df_oj$len)/sqrt(30),
			sd(df_vc$len)/sqrt(30),
			sd(df_half$len)/sqrt(20),
			sd(df_one$len)/sqrt(20),
			sd(df_two$len)/sqrt(20)
			)
	)
```
Neither the treatment nor the dosage groups have similar variances, therefore we use unequal variance t-tests.


```{r}
t <- t.test(len~supp, data=dftg, paired=FALSE, var.equal=FALSE)
data.frame(t$estimate, t$p.value)

t <- t.test(len~dose, data=rbind(df_half, df_one), paired=FALSE, var.equal=FALSE)
data.frame(t$estimate, t$p.value)

t <- t.test(len~dose, data=rbind(df_two, df_one), paired=FALSE, var.equal=FALSE)
data.frame(t$estimate, t$p.value)
```

The means of every group-pair are different, with p-values of 0.06 or better.

# Conclusions
Every experimental parameter caused some change in the tooth growth of a guinea pig population. From t-testing group pairs, we obtain the following results.

| Group | Mean Tooth Length | P-Value |
|-------|-------------------|---------|
| OJ | `r round(mean(df_oj$len),3)` | $0.06$ |
| VC | `r round(mean(df_vc$len),3)` | $0.06$ |
||||
| 0.5 mg | `r round(mean(df_half$len),3)` | $1.27 \times 10^{-7}$ |
| 1.0 mg | `r round(mean(df_one$len),3)` | $1.27 \times 10^{-7}$ |
||||
| 1.0 mg | `r round(mean(df_one$len),3)` | $1.91 \times 10^{-5}$ |
| 2.0 mg | `r round(mean(df_two$len),3)` | $1.91 \times 10^{-5}$ |

To obtain these results, we assume that each guinea pig group is experimentally independant, and has a variance unequal to that of any other group.


# Appendix: T-Test Results

```{r}
t.test(len~supp, data=dftg, paired=FALSE, var.equal=FALSE)
t.test(len~dose, data=rbind(df_half, df_one), paired=FALSE, var.equal=FALSE)
t.test(len~dose, data=rbind(df_two, df_one), paired=FALSE, var.equal=FALSE)
```
